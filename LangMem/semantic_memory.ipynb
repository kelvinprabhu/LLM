{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690f7ef7-9506-46fd-b9b8-f19dbc00ab23",
   "metadata": {},
   "source": [
    "# Semantic Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e0edc5-6096-4e6a-a107-d5e7588e897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langmem langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778e3a73-afba-4faf-83f2-715885149ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f3d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Load free model from Groq (you need a Groq API key)\n",
    "llm = ChatGroq(\n",
    "    api_key=\"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\",\n",
    "    model_name=\"mixtral-8x7b-32768\",  # or \"\", etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12ba70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm, tools=[], store=store, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7908d3b6-da10-497d-992c-77e6439d832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(agent, txt, thread_id):\n",
    "    result_state = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": txt}]}, config={\"configurable\": {\"thread_id\": thread_id}})\n",
    "    return result_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4e8d540-4f64-417d-9f65-27abc4b06f4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpcore/_sync/connection.py:156\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_tls\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 156\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpcore/_backends/sync.py:154\u001b[0m, in \u001b[0;36mSyncStream.start_tls\u001b[0;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[1;32m    150\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    151\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    153\u001b[0m }\n\u001b[0;32m--> 154\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/groq/_base_client.py:970\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m thread_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread-1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHi there, I\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mm training for a half marathon in 2 months - could you propose a daily training plan to prepare?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m, in \u001b[0;36mchat\u001b[0;34m(agent, txt, thread_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(agent, txt, thread_id):\n\u001b[0;32m----> 2\u001b[0m     result_state \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2719\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2720\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2723\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2724\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2725\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2728\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2730\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   2734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2436\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2437\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2438\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2439\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2441\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2442\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   2443\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:505\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StateSchema:\n\u001b[1;32m    504\u001b[0m     state \u001b[38;5;241m=\u001b[39m _get_model_input_state(state)\n\u001b[0;32m--> 505\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langchain_core/runnables/base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 776\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m         )\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/langchain_groq/chat_models.py:498\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    494\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    497\u001b[0m }\n\u001b[0;32m--> 498\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/groq/resources/chat/completions.py:368\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    231\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_settings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/groq/_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1224\u001b[0m     )\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/groq/_base_client.py:1002\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1002\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1006\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1011\u001b[0m )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error.",
      "\u001b[0mDuring task with name 'agent' and id '695bc4b3-e0de-7230-e749-185f4abeb3a6'"
     ]
    }
   ],
   "source": [
    "thread_1 = \"thread-1\"\n",
    "chat(agent, \"Hi there, I'm training for a half marathon in 2 months - could you propose a daily training plan to prepare?\", thread_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8289d65-440c-4bcd-959d-f160842b0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You got this! I wish you the best of luck on your half marathon training and the big day itself! May your runs be smooth, your hills be conquered, and your finish line be a joyful celebration of your hard work and dedication.\\n\\nRemember to stay focused, stay positive, and stay fueled. And don't forget to celebrate your small victories along the way, because every step you take brings you closer to your goal.\\n\\nYou've got this!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(agent, \"Nice! Wish me luck!\", thread_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b8907-9ee2-4969-836a-f32600a7d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think there might have been some misunderstanding! I didn't say anything prior to your message, so I'm not sure what you're thanking me for or referring to. If you'd like to talk about something specific, I'm here to listen and help if I can!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_2 = \"thread-2\"\n",
    "chat(agent, \"Nice! Oh thank you! It'll be hard.\", thread_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a26b13-e646-4a26-b289-a9b485b755e4",
   "metadata": {},
   "source": [
    "## Adding Memory\n",
    "\n",
    "We'll use regular tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: langmem in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (0.0.27)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sentence-transformers) (2.6.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sentence-transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: langchain-anthropic>=0.3.3 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (0.3.15)\n",
      "Requirement already satisfied: langchain-core>=0.3.46 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (0.3.65)\n",
      "Requirement already satisfied: langchain-openai>=0.3.1 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (0.3.11)\n",
      "Requirement already satisfied: langchain>=0.3.15 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (0.3.21)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.12 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (2.1.0)\n",
      "Requirement already satisfied: langgraph>=0.3.23 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (0.4.8)\n",
      "Requirement already satisfied: langsmith>=0.3.8 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (0.3.45)\n",
      "Requirement already satisfied: trustcall>=0.0.39 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langmem) (0.0.39)\n",
      "Requirement already satisfied: filelock in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain>=0.3.15->langmem) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain>=0.3.15->langmem) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain>=0.3.15->langmem) (2.0.38)\n",
      "Requirement already satisfied: anthropic<1,>=0.52.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain-anthropic>=0.3.3->langmem) (0.54.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain-core>=0.3.46->langmem) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain-core>=0.3.46->langmem) (1.33)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain-openai>=0.3.1->langmem) (1.69.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langchain-openai>=0.3.1->langmem) (0.9.0)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langgraph>=0.3.23->langmem) (0.2.2)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langgraph>=0.3.23->langmem) (0.1.70)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langgraph>=0.3.23->langmem) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langgraph-checkpoint>=2.0.12->langmem) (1.10.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langsmith>=0.3.8->langmem) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langsmith>=0.3.8->langmem) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langsmith>=0.3.8->langmem) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from langsmith>=0.3.8->langmem) (0.23.0)\n",
      "Requirement already satisfied: setuptools in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: dydantic<1.0.0,>=0.0.8 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from trustcall>=0.0.39->langmem) (0.0.8)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic>=0.3.3->langmem) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic>=0.3.3->langmem) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic>=0.3.3->langmem) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic>=0.3.3->langmem) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.8->langmem) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.8->langmem) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.8->langmem) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.8->langmem) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.46->langmem) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.3.15->langmem) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.3.15->langmem) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.3.15->langmem) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers langmem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf1c41-7fe8-4c79-8b6c-3a8fb7995ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"dims\": 1536,\n",
    "        \"embed\": \"openai:text-embedding-3-small\"\n",
    "    }\n",
    ")\n",
    "\n",
    "namespace = (\"agent_memories\",)\n",
    "memory_tools = [\n",
    "    create_manage_memory_tool(namespace),\n",
    "    create_search_memory_tool(namespace)\n",
    "]\n",
    "checkpointer = InMemorySaver()\n",
    "agent = create_react_agent(llm, tools=memory_tools, store=store, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f56f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3837580d10cf4a349a2c0e3d9120a6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fad87c678a407d86ebabf5035becb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66060f0d41a41939e788d551c4aed12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39a7ceadeb7469883833c842a172754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/b4515a8e32f81ab4fef65e10891fdb188bc45c4195620d447bc3263e132d9de5?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1750268220&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDI2ODIyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkL2I0NTE1YThlMzJmODFhYjRmZWY2NWUxMDg5MWZkYjE4OGJjNDVjNDE5NTYyMGQ0NDdiYzMyNjNlMTMyZDlkZTU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=RBikuCu6ZAIBOjZXbBp0PfFrBmUOdTLXfdOdW2usb8fPz9In6ckrj4VyzlixqYvfJfSkFzUBR84iE7ix5C%7E7pOmaWDUV5qMB-TqSR0Kwy9lryqVgnGH2Ho4%7E4MsnUffpQkpkljQ6DseGYkWC5aqAqhqiz6w63RnkV08MHdoF8C7HAf7IyC%7E-oXBIRgiengigwsiOyeYwJ%7EqTwdHc9Vs9eIvJK6UQFSPrJep3Untt5mkbzgJQbFQ8AMyTwerObt1HeR8mgIXKhI7l3uWn5zrsmX%7E1v-XVmlsmE52iOF1FjsKMdx9BAX8YiZXyDTwXV385IIr7SHxheZipWzAR3C9W6w__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b327c1e78d7e414b84fb3e6bb9edc179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   4%|4         | 430M/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/b4515a8e32f81ab4fef65e10891fdb188bc45c4195620d447bc3263e132d9de5?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1750268220&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDI2ODIyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkL2I0NTE1YThlMzJmODFhYjRmZWY2NWUxMDg5MWZkYjE4OGJjNDVjNDE5NTYyMGQ0NDdiYzMyNjNlMTMyZDlkZTU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=RBikuCu6ZAIBOjZXbBp0PfFrBmUOdTLXfdOdW2usb8fPz9In6ckrj4VyzlixqYvfJfSkFzUBR84iE7ix5C%7E7pOmaWDUV5qMB-TqSR0Kwy9lryqVgnGH2Ho4%7E4MsnUffpQkpkljQ6DseGYkWC5aqAqhqiz6w63RnkV08MHdoF8C7HAf7IyC%7E-oXBIRgiengigwsiOyeYwJ%7EqTwdHc9Vs9eIvJK6UQFSPrJep3Untt5mkbzgJQbFQ8AMyTwerObt1HeR8mgIXKhI7l3uWn5zrsmX%7E1v-XVmlsmE52iOF1FjsKMdx9BAX8YiZXyDTwXV385IIr7SHxheZipWzAR3C9W6w__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd8cad2b0764ba9ab7d76830eb041dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   4%|4         | 440M/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dab35a2557c4145aca55be29feb6acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec47ef775ab74e98813e53b025b205a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# from langchain.agents import create_react_agent\n",
    "# from langchain.llms import HuggingFaceHub  # or use your preferred LLM\n",
    "\n",
    "# # Example LLM (replace with your own)\n",
    "# from langchain_community.llms import HuggingFacePipeline\n",
    "# from transformers import pipeline\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# # Step 1: Define fitness trainer prompt template\n",
    "# fitness_prompt = PromptTemplate.from_template(\"\"\"\n",
    "# You are a professional AI fitness coach.\n",
    "\n",
    "# You help users by understanding their current fitness goals, routines, and body status.\n",
    "# You respond with empathy, scientific reasoning, and personalized plans.\n",
    "\n",
    "# User: {input}\n",
    "# \"\"\")\n",
    "\n",
    "# # Step 2: Load LLM\n",
    "# llm_pipeline = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\", max_new_tokens=512, do_sample=True)\n",
    "# llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# # Wrap it in LLMChain with prompt\n",
    "# fitness_chain = LLMChain(llm=llm, prompt=fitness_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06715ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Step 1: Use Hugging Face Embedding Model\n",
    "\n",
    "# Step 2: Setup vector store using custom embedder\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"dims\": 384,\n",
    "        \"embed\": embed_model.embed_query\n",
    "    }\n",
    ")\n",
    "# Step 3: Create memory tools\n",
    "namespace = (\"agent_memories\",)\n",
    "memory_tools = [\n",
    "    create_manage_memory_tool(namespace),\n",
    "    create_search_memory_tool(namespace)\n",
    "]\n",
    "\n",
    "# Step 4: Setup checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# from langchain.agents import create_react_agent, AgentExecutor\n",
    "# from langchain.llms import HuggingFaceHub  # or use your preferred LLM\n",
    "\n",
    "# # Example LLM (replace with your own)\n",
    "# from langchain_community.llms import HuggingFacePipeline\n",
    "# from transformers import pipeline\n",
    "\n",
    "# llm_pipeline = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\", max_new_tokens=256)\n",
    "# llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# Final Agent setup\n",
    "agent = create_react_agent(llm, tools=memory_tools, store=store, checkpointer=checkpointer)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=memory_tools, memory=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4edaea7-5554-4b12-af49-08e423b04577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a sample daily training plan to help you prepare for a half marathon in 2 months:\\n\\nMonday:\\n\\n* 30-minute easy run\\n* Strength training: focus on lower body (legs, glutes, calves)\\n\\nTuesday:\\n\\n* 30-minute interval training (alternate between 5-minute fast pace and 5-minute easy pace)\\n* Strength training: focus on core and upper body (arms, shoulders, back)\\n\\nWednesday:\\n\\n* Rest day or active recovery (e.g., light yoga or a short walk)\\n\\nThursday:\\n\\n* 30-minute hill repeats (find a route with hills and alternate between 5-minute fast pace and 5-minute easy pace on the hills)\\n* Strength training: focus on lower body (legs, glutes, calves)\\n\\nFriday:\\n\\n* 30-minute easy run\\n* Strength training: focus on core and upper body (arms, shoulders, back)\\n\\nSaturday:\\n\\n* 45-minute long run at a moderate pace\\n* Strength training: focus on lower body (legs, glutes, calves)\\n\\nSunday:\\n\\n* Rest day or active recovery (e.g., light yoga or a short walk)\\n\\nThis is just a sample plan and you may need to adjust it based on your current fitness level and goals. It's also important to listen to your body and rest when needed. Additionally, make sure to incorporate proper nutrition, hydration, and sleep to support your training.\\n\\nRemember to gradually increase your mileage and intensity over the next 2 months to allow your body to adapt and reduce the risk of injury. It's also important to include rest days and active recovery days to allow your body to recover and rebuild.\\n\\nGood luck with your training!\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_1 = \"thread-1\"\n",
    "chat(agent, \"Hi there, I'm training for a half marathon in 2 months - could you propose a daily training plan to prepare?\", thread_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b037a-ab09-43fb-addf-1969af81988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the mistakes. It seems that the tool calls I provided earlier are not correct. To provide a correct tool call, I would need more information about the tool definition for the \"manage_memory\" tool.\n",
      "\n",
      "Please provide the tool definition for the \"manage_memory\" tool, including the parameters and their types. I will then attempt to create a new tool call with the correct parameters.\n",
      "\n",
      "Additionally, I will make sure to review my previous responses to correct any mistakes and provide accurate tool calls.\n"
     ]
    }
   ],
   "source": [
    "print(chat(agent, \"Nice! Wish me luck! Please note down the detailed memories for me :)\", thread_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d3c7d-7ee1-46b4-ad6f-3ee849644575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I found your training schedule! For Week 3, here\\'s what you\\'re supposed to do:\\n\\nMonday: 4-mile easy run\\nTuesday: Cross-training or rest\\nWednesday: 5-mile run with intervals\\nThursday: Rest or light cross-training\\nFriday: 4-mile tempo run\\nSaturday: 7-mile long run\\nSunday: Rest or light walking\\n\\nRemember:\\n- Easy runs should be at a conversational pace\\n- Tempo runs should be at a \"comfortably hard\" pace\\n- Long runs should be at an easy, conversational pace\\n- Intervals should alternate between hard effort and recovery periods\\n- Stay hydrated and listen to your body\\n\\nWould you like me to remember any specific modifications or notes about how your training is going?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_2 = \"thread-2\"\n",
    "chat(agent, \"Remember what I'm supposed to do for my training this week? It's week 3...\", thread_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0cfb5-4fdb-4680-9c34-7eec063acbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've updated your training plan, specifically modifying weeks 3-4 to focus on low-impact activities while your ankle heals. The new plan for this week (Week 3) replaces running with alternative cardio activities:\\n\\n- Monday: Low-impact cross-training (swimming or cycling)\\n- Tuesday: Upper body strength training + Physical therapy exercises\\n- Wednesday: Pool running or cycling intervals\\n- Thursday: Rest + ankle rehabilitation exercises\\n- Friday: Stationary bike or elliptical (30-45 minutes)\\n- Saturday: Long session swimming or cycling (45-60 minutes)\\n- Sunday: Rest + gentle ankle mobility work\\n\\nI've also added injury-specific notes to the plan. Remember to:\\n1. Consult with a healthcare provider before returning to running\\n2. Follow the RICE protocol for your ankle\\n3. Only resume running when you're cleared and pain-free\\n\\nWould you like any clarification about the modified activities or additional adjustments to the plan?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(agent, \"That may be tricky. I just sprained my ankle. Could you update my plan to include more cross training? Be sure to update the existing key of our plan\", thread_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f562a4e-0ec5-4c70-8027-7791813ec644",
   "metadata": {},
   "source": [
    "## Different User Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba9529-1118-441b-941e-35ed2d127949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"dims\": 1536,\n",
    "        \"embed\": \"openai:text-embedding-3-small\"\n",
    "    }\n",
    ")\n",
    "\n",
    "namespace = (\"agent_memories\", \"{user_id}\")\n",
    "memory_tools = [\n",
    "    create_manage_memory_tool(namespace),\n",
    "    create_search_memory_tool(namespace)\n",
    "]\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_react_agent(\"anthropic:claude-3-5-sonnet-latest\", tools=memory_tools, store=store, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1736845-41f7-4ce3-8aec-436e18c8add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(agent, txt, thread_id, user_id):\n",
    "    result_state = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": txt}]}, \n",
    "                                config={\"configurable\": {\"thread_id\": thread_id, \"user_id\": user_id}})\n",
    "    return result_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa459758-3241-46b7-a1cc-38ee513d9db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've created a progressive 8-week training plan that will help you prepare for your half marathon. To help you stay accountable, you can check in with me regularly, and I'll be able to recall your training plan and progress. I can:\\n\\n1. Answer questions about specific training days\\n2. Help you adjust the plan if needed\\n3. Provide tips for specific aspects of training\\n4. Track your progress and achievements\\n5. Offer motivation and reminders\\n\\nWould you like me to help you with any specific aspect of the training plan? Also, it would be helpful to know:\\n- Your current running experience/fitness level\\n- Any previous running injuries or concerns\\n- Your target finish time (if you have one)\\n\\nThis information would help me provide more personalized advice and potentially adjust the training plan to better suit your needs.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_1 = \"thread-1\"\n",
    "user_id = \"User-A\"\n",
    "chat(agent, \n",
    "     \"Hi I'm Will, I'm training for a half marathon in 2 months - could you propose a daily training plan to prepare and help me stay honest??\",\n",
    "     thread_1,\n",
    "     user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8e615-58eb-4b02-9084-90acd4b063c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'd be happy to help you on your chess journey! To provide better guidance, it would be helpful to know:\\n\\n1. What's your current level in chess? (beginner, intermediate, etc.)\\n2. Do you already know the basic rules and piece movements?\\n3. Are you practicing regularly or just starting out?\\n4. Do you have any specific areas of the game you'd like to focus on (openings, tactics, endgame, etc.)?\\n\\nOnce you share more details about your current chess experience and specific goals, I can provide more targeted advice and help you develop a learning plan. Just let me know, and I'll update my understanding of your chess journey accordingly!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_1 = \"thread-2\"\n",
    "user_id2 = \"User-B\"\n",
    "chat(agent, \n",
    "     \"Hi I'm John, I'm learning chess - could you help me become great??\",\n",
    "     thread_1,\n",
    "     user_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f972317-4050-4af0-8353-3e1667c977e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on my memories, I only know that you're interested in chess, which while often considered a mind sport, isn't typically categorized as a traditional sport. I don't have any memories of you mentioning other sports that you like. If you'd like to tell me about any sports you enjoy, I'd be happy to remember that information for future conversations!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(agent, \n",
    "     \"Do you remember me liking any sports?\",\n",
    "     thread_1,\n",
    "     user_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592e7af-54c3-4e1e-bcfe-e5299b1606f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('agent_memories', 'User-A') {'content': 'User Will is training for a half marathon in 2 months. Goal event timeline: Approximately May 2024.'}\n",
      "('agent_memories', 'User-A') {'content': 'Half Marathon Training Plan for Will:\\n\\nWeek 1-2:\\n- Tuesday: 3 miles easy pace\\n- Thursday: 3 miles with middle mile at tempo pace\\n- Saturday: 4-5 miles long run\\n- Other days: Rest or cross-training\\n\\nWeek 3-4:\\n- Tuesday: 4 miles easy pace\\n- Thursday: 4 miles with tempo intervals\\n- Saturday: 6-7 miles long run\\n- Other days: Rest or cross-training\\n\\nWeek 5-6:\\n- Tuesday: 5 miles easy pace\\n- Thursday: 5 miles with speed work\\n- Saturday: 8-9 miles long run\\n- Other days: Rest or cross-training\\n\\nWeek 7-8:\\n- Tuesday: 5-6 miles easy pace\\n- Thursday: 5-6 miles with tempo runs\\n- Saturday: 10-11 miles long run\\n- Other days: Rest or cross-training\\n\\nFinal 2 weeks:\\n- Begin tapering\\n- Tuesday: 4 miles easy pace\\n- Thursday: 3 miles with light tempo\\n- Saturday (week before race): 6-8 miles\\n- Race week: Light 2-3 mile runs, rest 2 days before race\\n- Race day!\\n\\nKey Guidelines:\\n- Easy pace: Should be able to hold a conversation\\n- Tempo pace: Comfortably hard, about 20-30 seconds faster than easy pace\\n- Cross-training: Swimming, cycling, or strength training\\n- Stay hydrated and maintain proper nutrition\\n- Rest when needed and listen to your body\\n- Gradually increase distance to prevent injury'}\n",
      "('agent_memories', 'User-B') {'content': 'User John is learning chess and wants to become great at it. They are seeking help to improve their chess skills.'}\n"
     ]
    }
   ],
   "source": [
    "items = store.search((\"agent_memories\",))\n",
    "for item in items:\n",
    "    print(item.namespace, item.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f505cc-736f-4894-a214-1872ec8e17f7",
   "metadata": {},
   "source": [
    "## \"Eager\" memory retrieval\n",
    "\n",
    "We can fetch memories before the first LLM call to simplify its response. Otherwise, it has known and unknown unknowns so will almost always try to search for some subclass of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ceedf-7c3b-4609-9bb3-542c94f71c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langgraph.config import get_store\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"dims\": 1536,\n",
    "        \"embed\": \"openai:text-embedding-3-small\"\n",
    "    }\n",
    ")\n",
    "\n",
    "namespace = (\"agent_memories\",)\n",
    "memory_tools = [\n",
    "    create_manage_memory_tool(namespace),\n",
    "    create_search_memory_tool(namespace)\n",
    "]\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "def prompt(state):\n",
    "    # Search over memories based on the messages\n",
    "    store = get_store()\n",
    "    items = store.search(namespace, query=state[\"messages\"][-1].content)\n",
    "    memories = \"\\n\\n\".join(str(item) for item in items)\n",
    "    system_msg = {\"role\": \"system\", \"content\": f\"## Memories:\\n\\n{memories}\"}\n",
    "    return [system_msg] + state[\"messages\"]\n",
    "    \n",
    "agent = create_react_agent(\"anthropic:claude-3-5-sonnet-latest\", prompt=prompt, tools=memory_tools, store=store, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667804de-3b2b-46cd-ac1b-9cd3e01aa9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've created an 8-week training plan for your half marathon preparation. The plan gradually increases your mileage while incorporating different types of runs and adequate rest periods. Here's a breakdown of the key components:\\n\\n1. Weekly Structure:\\n- 3-4 running days\\n- 2 rest/cross-training days\\n- 1 long run day (typically Saturday)\\n- 1 complete rest or active recovery day (Sunday)\\n\\n2. Types of Runs:\\n- Easy runs: Build base endurance\\n- Interval training: Improve speed and running economy\\n- Long runs: Build endurance and prepare for race distance\\n- Tempo runs: Improve running efficiency\\n\\n3. Progressive Build-up:\\n- Weeks 1-2: Building base mileage\\n- Weeks 3-4: Increasing distance\\n- Weeks 5-6: Peak training weeks\\n- Week 7: Maximum long run\\n- Week 8: Taper week for race preparation\\n\\nThe plan assumes you can already run 3-4 miles comfortably. If this isn't the case, please let me know, and I can adjust the plan accordingly. Also, if you have any specific concerns or constraints (like previous injuries or schedule limitations), I can modify the plan to better suit your needs.\\n\\nWould you like me to elaborate on any specific aspect of the training plan?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_1 = \"thread-1\"\n",
    "chat(agent, \"Hi there, I'm training for a half marathon in 2 months - could you propose a daily training plan to prepare?\", thread_1, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c7701-1a41-4219-8b7d-a3a241afa58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've already stored the detailed training plan in the memories (as shown in the previous interaction), so you'll be able to refer back to it anytime! The memory includes the complete 8-week schedule, including daily workouts and important tips about hydration, rest, and cross-training.\n",
      "\n",
      "Good luck with your half marathon training! Remember to:\n",
      "1. Start gradually and follow the progression\n",
      "2. Listen to your body\n",
      "3. Stay consistent with your training\n",
      "4. Keep hydrated and maintain good nutrition\n",
      "5. Get adequate rest between sessions\n",
      "\n",
      "Feel free to come back anytime if you need to review the training plan or have questions about specific aspects of your training. The detailed plan will be here in the memories ready for you to access!\n"
     ]
    }
   ],
   "source": [
    "print(chat(agent, \"Nice! Wish me luck! Please note down the detailed memories for me :)\", thread_1, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f2ab4-837c-4867-8788-562010cbfa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let me check your half marathon training plan. Based on your training schedule for Week 3-4, here's what you should be doing:\\n\\nWeek 3 Schedule:\\n- Monday: 4 mile easy run\\n- Tuesday: Cross-training or rest\\n- Wednesday: 5 mile run with intervals (2 min fast, 2 min recover)\\n- Thursday: Rest or light cross-training\\n- Friday: 4 mile easy run\\n- Saturday: 7-8 mile long run\\n- Sunday: Rest or light walk\\n\\nRemember:\\n- During your intervals on Wednesday, alternate between 2 minutes of faster pace and 2 minutes of recovery pace\\n- Your easy runs should be at a comfortable, conversational pace\\n- For your weekend long run, you can choose between 7-8 miles depending on how you're feeling\\n- Listen to your body and make sure to stay hydrated\\n- Cross-training options include swimming, cycling, or strength training\\n\\nIs there anything specific about any of these workouts you'd like me to explain further?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_2 = \"thread-2\"\n",
    "chat(agent, \"What I'm supposed to do for my training this week? It's week 3...\", thread_2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7f269-ae7e-4134-86f9-fe2d5dec9e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linux-deep-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
